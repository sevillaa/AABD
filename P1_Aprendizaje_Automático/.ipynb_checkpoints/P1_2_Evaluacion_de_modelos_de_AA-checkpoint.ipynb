{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 1: Aprendizaje Automático\n",
    "## Parte A: Evaluación de modelos de Aprendizaje Automático\n",
    "Hecho por:\n",
    "- Jaime Benedí\n",
    "- Miguel Sevilla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta parte vamos a utilizar la librería [surprise](https://surprise.readthedocs.io/en/stable/) que implementa algoritmos y otros procedimientos para desarrollar y evaluar algoritmos de sistemas de recomendación. Asegúrate de tenerla instalada antes de empezar a hacer las tareas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trabajaremos sobre el dataset de [MovieLens de 100K](https://grouplens.org/datasets/movielens/100k/). MovieLens es un dataset muy usado en el desarrollo y evaluación de sistemas de recomendación, y el dataset de 100k contiene 100K interacciones entre usuarios y productos, almacenando qué usuario ha puntuado qué película y con qué rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos\n",
    "1. Cargar MovieLens de 100k.\n",
    "\n",
    "2. Divide el dataset en una partición simple, donde el conjunto de evaluación sea el 75% de las interacciones y el resto forme parte del conjunto de evaluación. Aquí tenéis que pasarle random_state = SEED a la función.\n",
    "\n",
    "3. Vamos a evaluar distintos algoritmos de recomendación:\n",
    "   1. Filtrado colaborativo basado en vecinos (KNNBasic en esta [librería](https://surprise.readthedocs.io/en/stable/knn_inspired.html)) tanto basado en usuarios como enproductos. Utilizaremos la métrica de similitud de Pearson.\n",
    "   2. Filtrado colaborativo basado en modelos usando [factorización de matrices](https://surprise.readthedocs.io/en/stable/matrix_factorization.html), usando los algoritmos de SVD y NMF.\n",
    "\n",
    "4. Cada uno de estos algoritmos se entrenarán con el conjunto de\n",
    "entrenamiento. Aquí tenéis que pasarle random_state = SEED a cada uno de los modelos.\n",
    "\n",
    "5. Después se obtendrán las predicciones que todos los algoritmos obtienen para el conjunto de evaluación. Muestra el resultado de 5 predicciones e interpreta los resultados.\n",
    "\n",
    "6. Crea una tabla con los valores que se obtienen para las métricas de evaluación RMSE, precision@k, recall@k, y NDCG, k es el tamaño de la lista de recomendación y será k = 10. Surprise solo implementa RMSE. Las demás las podéis encontrar en sklearn usando precision_score, recall_score, ndcg_score.\n",
    "   1. **IMPORTANTE**: solo las películas cuyo rating sea superior a 4 serán consideradas relevantes (incluyendo en la lista de películas recomendadas por el modelo).\n",
    "\n",
    "7. Explica cada uno de los resultados obtenidos y qué significado tienen. Determina cuál podría ser el mejor método recomendador a utilizar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Antes de empezar...\n",
    "Determina un valor para una variable SEED (el que sea). Esta variable se la vamos a pasar a los modelos para que cada vez que se ejecute el código salgan los mismos resultados. De esta forma os aseguráis de que los resultados que os salgan serán los mismos que me salgan a mí al ejecutar el código. Si no hacéis esto, vuestro análisis puede no tener ningún sentido en mi ejecución y os arriesgáis al no apto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, SVD\n",
    "from surprise.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 -> Cargar el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = Dataset.load_builtin(\"ml-100k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 -> Dividir el dataset:\n",
    "75% conjunto de evaluación (Posible errata -> ¿Entrenamiento?)\n",
    " \n",
    " pasarle random_state = SEED a la función -> facilita la reproducibilidad de los experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import train_test_split\n",
    "trainset, testset = train_test_split(data, test_size=0.25,random_state = SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Algoritmo de recomendación: KNNBasic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBasic at 0x11314a0f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import Dataset, KNNBasic,accuracy\n",
    "\n",
    "# Creamos el set de entrenamiento\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "# Construimos el algoritmo y lo entrenamos\n",
    "algoKNN = KNNBasic(random_state = SEED)\n",
    "algoKNN.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.7789\n"
     ]
    }
   ],
   "source": [
    "# Generar predicciones en el conjunto de prueba\n",
    "predictionsKNN = algoKNN.test(testset)\n",
    "\n",
    "# Calcular el RMSE para evaluar el error del modelo\n",
    "rmseKNN  = accuracy.rmse(predictionsKNN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE (Root Mean Squared Error) -> mide la precisión del modelo, cuanto menor sea esta mayor sera la capacidad del modelo para hacer sus predicciones. 0.7789 es un valor aceptable , sin embargo para saber cual es el mas adecuado para este dataset vamos a calcular primero el SVD y el NMF para comparar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Algoritmo de recomendación: SVD y NMF\n",
    " \n",
    "## SVD (Single Value Decomposition)\n",
    " Tecnica matematica que permite descomponer una matriz en tres matrices A = u∑V^T\n",
    " - U -> Matriz vectores singulares izquierdos (direcciones principales en el espacio original de los datos)\n",
    " - ∑ -> Matriz diagonal con los valores singulares (\"fuerza\" de cada direccion)\n",
    " - V^T -> Traspuesta de la matriz de vectores singulares derechos , dan una base para el espacio de las variables\n",
    "\n",
    " Esta composicion permite entender la estructura de la información contenida en A, al conservar solo los componentes más importantes (mayor valor singular), se reduce la dimensionalidad de los datos y se elimina el ruido.\n",
    "\n",
    " En sistemas de recomendación, la matriz A representa las calificaciones de usuarios a diferentes ítems. Debido a que esta matriz es muy dispersa (muchos datos faltantes), no es posible aplicar directamente la SVD clásica. En su lugar, se aproxima la matriz mediante una factorización en componentes latentes, buscando un ajuste óptimo que minimice el error sobre las calificaciones conocidas.\n",
    " \n",
    " Al ejecutar algoSVD.fit(trainset), el algoritmo estima μ,bu,bi,pu y qi:\n",
    "- μ -> calificación pormedio global\n",
    "- bu -> sesgo del usuario u \n",
    "- bi -> sesgo del item\n",
    "- pu -> vector de factores latentes del usuario (resume las características o preferencias ocultas del usuario)\n",
    "- qi -> vector de factores latentes del item i (Descripción del producto a través de un vector de N factores                   latentes)\n",
    "\n",
    " La función algoSVD.test(testset) utiliza estos paremtros para predecir las calificaciones en el conjunto de prueba\n",
    "\n",
    " Y por ultimo RMSE mide la precisión de las predicciones (RMSE -> medida que indica como de lejos están las predicciones de los valores reales , por lo tanto a menor valor mejor modelo)\n",
    "\n",
    " ## NMF (Non-Negative Matriz Factorization)\n",
    " Tecnica de fcatorización de matrices que descompone una matriz A en dos matrices no negativas, A ≈ W . H\n",
    " \n",
    " - W es la matriz de factores latetes de los usuarios (fila -> usuario , columna -> caracteristica latente)\n",
    " - H es la matriz de factores latentes de los items (columna -> item, fila -> carcaterística latente\n",
    "\n",
    " En este ejemplo como estamos trabajando con peliculas, los factores latentes podrían representar características como   accíon, suspense o romántico, y cada película tendría una cantidad de estas, siempre con numeros positivos, evitando   que se cancelen entre si.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.6757\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from surprise import accuracy\n",
    "\n",
    "algoSVD = SVD(random_state = SEED)\n",
    "\n",
    "# Entrenar el algoritmo con el trainset y predecir los ratios para el test\n",
    "algoSVD.fit(trainset)\n",
    "predictionsSVD = algoSVD.test(testset)\n",
    "\n",
    "rmseSVD = accuracy.rmse(predictionsSVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8233\n"
     ]
    }
   ],
   "source": [
    "from surprise import NMF\n",
    "\n",
    "# Crear una instancia del modelo NMF con la misma semilla para comparar\n",
    "algoNMF = NMF(random_state=SEED)\n",
    "\n",
    "# Entrenar el modelo en el conjunto de entrenamiento\n",
    "algoNMF.fit(trainset)\n",
    "\n",
    "# Predecir las calificaciones para el conjunto de prueba\n",
    "predictionsNMF = algoNMF.test(testset)\n",
    "\n",
    "# Calcular el RMSE para evaluar el error del modelo\n",
    "rmseNMF = accuracy.rmse(predictionsNMF)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El RMSE empleando este algoritmo (NMF) y el algoritmo KNN son mayores que el de SVD por lo tanto SVD tiene un mejor desempeño en este caso y el algoritmo más recomendado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Muestra el resultado de 5 predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones KNN\n",
      "Usuario 391 - Película 591 | Real: 4.0 | Prediccion: 3.63\n",
      "Usuario 181 - Película 1291 | Real: 1.0 | Prediccion: 1.94\n",
      "Usuario 637 - Película 268 | Real: 2.0 | Prediccion: 2.82\n",
      "Usuario 332 - Película 451 | Real: 5.0 | Prediccion: 3.92\n",
      "Usuario 271 - Película 204 | Real: 4.0 | Prediccion: 3.95\n",
      "\n",
      "Predicciones SVD\n",
      "Usuario 391 - Película 591 | Real: 4.0 | Prediccion: 3.54\n",
      "Usuario 181 - Película 1291 | Real: 1.0 | Prediccion: 1.00\n",
      "Usuario 637 - Película 268 | Real: 2.0 | Prediccion: 2.42\n",
      "Usuario 332 - Película 451 | Real: 5.0 | Prediccion: 4.45\n",
      "Usuario 271 - Película 204 | Real: 4.0 | Prediccion: 3.74\n",
      "\n",
      "Predicciones NMF\n",
      "Usuario 391 - Película 591 | Real: 4.0 | Prediccion: 3.61\n",
      "Usuario 181 - Película 1291 | Real: 1.0 | Prediccion: 1.00\n",
      "Usuario 637 - Película 268 | Real: 2.0 | Prediccion: 2.46\n",
      "Usuario 332 - Película 451 | Real: 5.0 | Prediccion: 4.38\n",
      "Usuario 271 - Película 204 | Real: 4.0 | Prediccion: 3.81\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicciones KNN\")\n",
    "for pred in predictionsKNN[:5]:  # Tomar las primeras 5\n",
    "    uid, iid, true_r, est, _ = pred\n",
    "    print(f\"Usuario {uid} - Película {iid} | Real: {true_r} | Prediccion: {est:.2f}\")\n",
    "\n",
    "print(\"\\nPredicciones SVD\")\n",
    "for pred in predictionsSVD[:5]:  # Tomar las primeras 5\n",
    "    uid, iid, true_r, est, _ = pred\n",
    "    print(f\"Usuario {uid} - Película {iid} | Real: {true_r} | Prediccion: {est:.2f}\")\n",
    "\n",
    "print(\"\\nPredicciones NMF\")\n",
    "for pred in predictionsNMF[:5]:  # Tomar las primeras 5\n",
    "    uid, iid, true_r, est, _ = pred\n",
    "    print(f\"Usuario {uid} - Película {iid} | Real: {true_r} | Prediccion: {est:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN tiende a alejarse más de los valores reales como por ejemplo en el caso 2 donde el rating real es 1 y sin embargo predice 1,94 así como en el caso 4 predice 3,95 cuando el valor real es 5. Esto quiere decir que filtrar en base a vecinos (KNN) no es tan preciso en este contexto.\n",
    "Por otro lado SVD y NMF son más precisos , destacando el SVD que como se predecía con su valor de RMSE (el más bajo de los 3) es el que más se aproxima en la mayoría de casos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6: Tabla con los valores de RMSE, precision@k, recall@k, y NDCG,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " k es el tamaño de la lista de recomendación y será k = 10. Sklearn para precision_score, recall_score, ndcg_score.\n",
    " \n",
    " Rating superior o igual a 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn.metrics, necesita convertir los valores en listas numpy.\n",
    "from sklearn.metrics import precision_score, recall_score, ndcg_score\n",
    "import pandas as pd\n",
    "\n",
    "#1-> Valores a 0 o 1 , siendo 1 relevante y 0 no relevante, para > 4 entonces relevante\n",
    "def get_binary_relevance(predictions):\n",
    "    #Valores reales a binarios\n",
    "    y_true = [1 if true_r >= 4 else 0 for (_, _, true_r, _, _) in predictions]\n",
    "    #Valores predicciones a binarios\n",
    "    y_pred = [1 if est >=4 else 0 for (_, _, _, est, _) in predictions]\n",
    "    return y_true, y_pred\n",
    "    \n",
    "y_true_knn, y_pred_knn = get_binary_relevance(predictionsKNN)\n",
    "y_true_svd, y_pred_svd = get_binary_relevance(predictionsSVD)\n",
    "y_true_nmf, y_pred_nmf = get_binary_relevance(predictionsNMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2-> Función para calcular precisión, recall y NDCG\n",
    "def calcula_metricas(y_true, y_pred, k=10):\n",
    "    #Proporción de predicciones positivas correctas\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    #Proporción de elementos relevantes que han sido identificados                           \n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    #Evaluar la calidad del ranking (k limita el calculo a el top k elementos\n",
    "    ndcg = ndcg_score([y_true], [y_pred], k=k)  # NDCG@K\n",
    "    return precision, recall, ndcg\n",
    "    \n",
    "# Calcular métricas para cada modelo\n",
    "precisionKNN, recallKNN, ndcgKNN = calcula_metricas(y_true_knn, y_pred_knn)\n",
    "precisionSVD, recallSVD, ndcgSVD = calcula_metricas(y_true_svd, y_pred_svd)\n",
    "precisionNMF, recallNMF, ndcgNMF = calcula_metricas(y_true_nmf, y_pred_nmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Modelo      RMSE  Precision@10  Recall@10   NDCG@10\n",
      "0    KNN  0.778858      0.944406   0.486473  0.944406\n",
      "1    SVD  0.675727      0.961173   0.488056  0.961173\n",
      "2    NMF  0.823313      0.896519   0.409555  0.896519\n"
     ]
    }
   ],
   "source": [
    "# Crear la tabla con todos los resultados\n",
    "results = pd.DataFrame({\n",
    "    \"Modelo\": [\"KNN\", \"SVD\", \"NMF\"],\n",
    "    \"RMSE\": [rmseKNN, rmseSVD, rmseNMF],  # Ya los tienes calculados\n",
    "    \"Precision@10\": [precisionKNN, precisionSVD, precisionNMF],\n",
    "    \"Recall@10\": [recallKNN, recallSVD, recallNMF],\n",
    "    \"NDCG@10\": [ndcgKNN, ndcgSVD, ndcgNMF]\n",
    "})\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Menor RMSE -> Mejor -> SVD\n",
    "\n",
    "Precision(% peliculas realmente importantes) -> Mayor Precison -> Mejor -> SVD\n",
    "\n",
    "Recall(% peliculas relevantes recomendadas) -> Mayor Recall -> Mejor -> SVD\n",
    "\n",
    "NDCG(peliculas mas relevantes en primeras posiciones) -> Mayor NDCG -> Mejor -> SVD\n",
    "\n",
    "El mejor modelo claramente es SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "583add762d6118f8268304ac9f7b352ed5f84ca41d2ef9a229497e39db3662bc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
